{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "from tensorflow import keras \n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator \n",
    "from tensorflow.keras import layers \n",
    "from tensorflow.keras import models \n",
    "from tensorflow.keras import optimizers \n",
    "from tensorflow.keras import backend as k \n",
    "from keras.models import load_model \n",
    "from keras import backend as K \n",
    "from keras.models import Sequential  \n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout ,Reshape \n",
    "import os \n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib as mpl \n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add path to directories\n",
    "train_dir=r'C:\\Users\\abhis\\Downloads\\archive\\chest_xray\\train' \n",
    "val_dir=r'C:\\Users\\abhis\\Downloads\\archive\\chest_xray\\val' \n",
    "test_dir=r'C:\\Users\\abhis\\Downloads\\archive\\chest_xray\\test' \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CREATING DATAGENERATERS FOR DATA AUGEMENTATION\n",
    "train_datagen = ImageDataGenerator( \n",
    "    rescale = 1./255, \n",
    "    rotation_range  = 40, \n",
    "    width_shift_range = 0.2, \n",
    "    height_shift_range = 0.2, \n",
    "    shear_range = 0.2, \n",
    "    zoom_range = 0.2, \n",
    "    horizontal_flip = True) \n",
    " \n",
    "val_datagen = ImageDataGenerator(rescale = 1./255) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = train_datagen.flow_from_directory( \n",
    "            train_dir, \n",
    "            target_size = (180,180), \n",
    "            batch_size = 32, \n",
    "            class_mode = 'binary') \n",
    " \n",
    " \n",
    "validation_generator = val_datagen.flow_from_directory( \n",
    "            test_dir, \n",
    "            target_size = (180,180), \n",
    "            batch_size = 32, \n",
    "            class_mode = 'binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL FOR TRAINING\n",
    "model=models.Sequential() \n",
    " \n",
    "model.add(Conv2D(64, (3, 3), activation='relu', padding='valid', input_shape=(180,180, 3))) \n",
    "model.add(Conv2D(64, (3, 3), activation='relu', padding='valid')) \n",
    "model.add(Conv2D(64, (3, 3), activation='relu', padding='valid')) \n",
    "\n",
    "model.add(MaxPooling2D((2, 2), strides=(2, 2))) \n",
    "\n",
    "model.add(Conv2D(128, (3, 3), activation='relu', padding='valid')) \n",
    "model.add(Conv2D(128, (3, 3), activation='relu', padding='valid')) \n",
    "model.add(Conv2D(128, (3, 3), activation='relu', padding='valid')) \n",
    "\n",
    "model.add(MaxPooling2D((2, 2), strides=(2, 2))) \n",
    "\n",
    "model.add(Conv2D(256, (3, 3), activation='relu', padding='valid')) \n",
    "model.add(Conv2D(256, (3, 3), activation='relu', padding='valid')) \n",
    "model.add(Conv2D(256, (3, 3), activation='relu', padding='valid')) \n",
    "\n",
    "model.add(MaxPooling2D((2, 2), strides=(2, 2))) \n",
    "\n",
    "model.add(Conv2D(500, (3, 3), activation='relu', padding='valid')) \n",
    "model.add(Conv2D(500, (3, 3), activation='relu', padding='valid')) \n",
    "\n",
    "model.add(MaxPooling2D((2, 2), strides=(2, 2))) \n",
    "\n",
    "model.add(Flatten()) \n",
    "model.add(Dense(256,activation='relu')) \n",
    "model.add(Dense(128,activation='relu')) \n",
    "model.add(Dense(1,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import optimizers \n",
    "model.compile(optimizer=optimizers.RMSprop(learning_rate=2e-4), loss='binary_crossentropy', \n",
    "metrics=['acc']) \n",
    "checkpoint_cb=keras.callbacks.ModelCheckpoint(\"best.h5\",save_best_only=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()# Load the saved model \n",
    "saved_model = load_model(\"best.h5\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now you can use the loaded model for making predictions or further training \n",
    "# For example, if you have a test generator for evaluation: \n",
    "test_generator = val_datagen.flow_from_directory( \n",
    "    test_dir, \n",
    "    target_size=(180, 180), \n",
    "    batch_size=32, \n",
    "    class_mode='binary' \n",
    ") \n",
    "evaluation = saved_model.evaluate(test_generator) \n",
    "print(f\"Test Loss: {evaluation[0]}, Test Accuracy: {evaluation[1]}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Or, if you want to make predictions on new data: \n",
    " \n",
    " predictions = saved_model.predict(test_generator)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
